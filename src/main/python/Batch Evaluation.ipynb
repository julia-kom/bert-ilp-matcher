{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Evaluation\n",
    "Set the folder parameter. Get an anaysis about all included batch evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "import pathlib\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "#set path to folder\n",
    "folder = \"../../../eval-results/_server-results/test18_ppp\"\n",
    "net_analysis = \"../../../eval-results/_server-results/net-BP-sap/net.eval\" \n",
    "gs_analysis = \"../../../eval-results/_server-results/goldstandard-sap-analysis/goldstandard.eval\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#fetch data \n",
    "dir_list = next(os.walk(folder))[1]\n",
    "dfs = []\n",
    "#merge all \n",
    "for subfolder in dir_list:\n",
    "    #print(subfolder)\n",
    "    evalFile = folder +\"/\" + subfolder +\"/aggRetrospectiveResults.eval\"\n",
    "    confFile = folder +\"/\" + subfolder +\"/config.log\"\n",
    "    if os.path.exists(evalFile):\n",
    "        df = pd.read_csv(evalFile ,encoding=\"ISO-8859-1\", skipinitialspace=True)\n",
    "        with open(confFile) as json_file:\n",
    "            conf = json.load(json_file)\n",
    "        #add config information to dataframe \n",
    "        df['matcher'] = conf['matcher']['ilp'] + \" - \" + conf['matcher']['profile'] +\" - \" + str(conf['matcher']['word-sim']) + \" - sim-weight=\" + str(conf['matcher']['sim-weight']) + \" - match-postprocessing=\" + str(conf['matcher']['postprocessing-thresh']) \n",
    "        df['matcher_wo_weight'] = conf['matcher']['ilp'] + \" - \" + conf['matcher']['profile'] +\" - \" + str(conf['matcher']['word-sim']) + \" - match-postprocessing=\" + str(conf['matcher']['postprocessing-thresh']) \n",
    "        df['complex-matches'] = conf['matcher']['complex matches']\n",
    "        df['profile'] = conf['matcher']['profile']\n",
    "        df['ilp'] =  conf['matcher']['ilp']\n",
    "        df['word-sim'] =  conf['matcher']['word-sim']\n",
    "        df['sim-weight'] = conf['matcher']['sim-weight']\n",
    "        df['matcher-postprocessing-threshold'] = conf['matcher']['postprocessing-thresh']\n",
    "        df['eval-postprocessing-threshold'] = conf['evaluation']['postprocessing-thresh']\n",
    "        #df.set_index(['Name','matcher'])\n",
    "        dfs.append(df)\n",
    "        \n",
    "df_combined = pd.concat(dfs)\n",
    "\n",
    "#convert time\n",
    "df_combined['OVERALL TIME'] = df_combined['OVERALL TIME'].map(lambda x: x / 1000000000.)\n",
    "df_combined['BP TIME'] = df_combined['BP TIME'].map(lambda x: x / 1000000000.)\n",
    "df_combined['LABEL-SIM TIME'] = df_combined['LABEL-SIM TIME'].map(lambda x: x / 1000000000.)\n",
    "df_combined['LP TIME'] = df_combined['LP TIME'].map(lambda x: x / 1000000000.)\n",
    "\n",
    "#extend with net information stored in net_analysis\n",
    "df_nets = pd.read_csv(net_analysis ,encoding=\"ISO-8859-1\", skipinitialspace=True)\n",
    "#df_nets['Name'] = df_nets.apply(lambda row: pnml_remover(row), axis=1)\n",
    "df_nets = df_nets.set_index('Name')\n",
    "#extend with goldstandard information stored in gs_analysis\n",
    "df_gss = pd.read_csv(gs_analysis ,encoding=\"ISO-8859-1\", skipinitialspace=True)\n",
    "df_gss = df_gss.set_index('Nets')\n",
    "def net1adder(row):\n",
    "    #get net names\n",
    "    if row['Name'] != \"Aggregated (MICRO)\" and row['Name'] != \"Aggregated (MACRO)\":\n",
    "        return row['Name'].split('-')[0].replace(\".pnml\",\"\")\n",
    "    else:\n",
    "        return 0\n",
    "def net2adder(row):        \n",
    "    if row['Name'] != \"Aggregated (MICRO)\" and row['Name'] != \"Aggregated (MACRO)\":\n",
    "        return row['Name'].split('-')[1].split('.')[0].replace(\".pnml\",\"\")\n",
    "    else: \n",
    "        return 0\n",
    "    \n",
    "def pnml_remover(row):\n",
    "    #get net names\n",
    "    if row['Name'] != \"Aggregated (MICRO)\" and row['Name'] != \"Aggregated (MACRO)\":\n",
    "        return row['Name'].replace(\".pnml\",\"\").replace(\".rdf\",\"\")\n",
    "    else:\n",
    "        return row['Name']\n",
    "\n",
    "def net1NonTaus(row):\n",
    "    if row['Name'] != \"Aggregated (MICRO)\" and row['Name'] != \"Aggregated (MACRO)\":\n",
    "        return df_nets.at[row['net1'],'nNonSilentTransitions'] \n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def net2NonTaus(row):\n",
    "    if row['Name'] != \"Aggregated (MICRO)\" and row['Name'] != \"Aggregated (MACRO)\":\n",
    "        return df_nets.at[row['net2'],'nNonSilentTransitions'] \n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def sumNonTaus(row):    \n",
    "    if row['Name'] != \"Aggregated (MICRO)\" and row['Name'] != \"Aggregated (MACRO)\":\n",
    "        return (row['net1NonTaus'] + row['net2NonTaus'])/2\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def correspondencesAdder(row, col):\n",
    "    #get net names\n",
    "    if row['Name'] != \"Aggregated (MICRO)\" and row['Name'] != \"Aggregated (MACRO)\":\n",
    "        s = row['Name']+\".rdf\"\n",
    "        return df_gss.at[s,col] \n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "df_combined['net1'] = df_combined.apply(lambda row: net1adder(row), axis=1)\n",
    "df_combined['net2'] = df_combined.apply(lambda row: net2adder(row), axis=1)\n",
    "#df_combined['net1NonTaus'] = df_combined.apply(lambda row: net1NonTaus(row), axis=1)\n",
    "#df_combined['net2NonTaus'] = df_combined.apply(lambda row: net2NonTaus(row), axis=1)\n",
    "#df_combined['sumNonTaus'] = df_combined.apply(lambda row: sumNonTaus(row), axis=1)\n",
    "df_combined['Name'] = df_combined.apply(lambda row: pnml_remover(row), axis=1)\n",
    "\n",
    "df_combined['GS_correspondences'] = df_combined.apply(lambda row: correspondencesAdder(row, 'correspondences'), axis=1)\n",
    "df_combined['GS_simple'] = df_combined.apply(lambda row: correspondencesAdder(row, 'simple'), axis=1)\n",
    "df_combined['GS_complex'] = df_combined.apply(lambda row: correspondencesAdder(row, 'complex'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#BASIC VISUALIZATION\n",
    "\n",
    "# visualize Precision \n",
    "g = sns.catplot(x=\"Name\", y=\"PRECISION\", hue=\"matcher\", kind=\"bar\", data=df_combined,  height=5, aspect=4);\n",
    "g.set_xticklabels(rotation=90)\n",
    "\n",
    "# Visualize Recall\n",
    "g = sns.catplot(x=\"Name\", y=\"RECALL\", hue=\"matcher\", kind=\"bar\", data=df_combined,  height=5, aspect=4);\n",
    "g.set_xticklabels(rotation=90)\n",
    "\n",
    "# Visualize FSCORE\n",
    "g = sns.catplot(x=\"Name\", y=\"FSCORE\", hue=\"matcher\", kind=\"bar\", data=df_combined,  height=5, aspect=4);\n",
    "g.set_xticklabels(rotation=90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Avg Precisision Recall Fscore over postprocessing threshold\n",
    "df_macro_avg = df_combined[df_combined.Name == \"Aggregated (MACRO)\"]\n",
    "df_micro_avg = df_combined[df_combined.Name == \"Aggregated (MICRO)\"]\n",
    "#write to excel\n",
    "with pd.ExcelWriter('batch-eval.xlsx') as writer:  \n",
    "    df_macro_avg.to_excel(writer, sheet_name='Macro')\n",
    "    df_micro_avg.to_excel(writer, sheet_name='Micro')\n",
    "    df_combined.to_excel(writer, sheet_name='All')\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "fig.set_size_inches(18.5, 5.25)\n",
    "sns.lineplot(x=\"eval-postprocessing-threshold\", y=\"RECALL\", hue=\"sim-weight\", data=df_macro_avg, ax = ax1, palette= sns.color_palette(\"Reds_d\", 11));\n",
    "ax1.set_title(\"Macro\")\n",
    "ax1.set_ylabel(\"Recall\")\n",
    "ax1.set_ylim([0.0,1.0])\n",
    "ax1.set_xlabel(\"Post-processing Threshold\")\n",
    "ax1.get_legend().remove()\n",
    "my_cmap = ListedColormap(sns.color_palette(\"Reds_d\", 11).as_hex())\n",
    "sm = plt.cm.ScalarMappable(cmap=my_cmap)\n",
    "cbar = fig.colorbar(sm, ax=ax1)\n",
    "cbar.ax.set_visible(False)\n",
    "cbar.ax.set_xlabel('sim-weight', rotation=0)\n",
    "sns.lineplot(x=\"eval-postprocessing-threshold\", y=\"RECALL\", hue=\"sim-weight\", data=df_micro_avg, ax = ax2, palette= sns.color_palette(\"Reds_d\", 11));\n",
    "ax2.set_title(\"Micro\")\n",
    "ax2.set_ylim([0.0,1.0])\n",
    "ax2.set_ylabel(\"Recall\")\n",
    "ax2.set_xlabel(\"Post-processing Threshold\")\n",
    "ax2.get_legend().remove()\n",
    "my_cmap = ListedColormap(sns.color_palette(\"Reds_d\", 11).as_hex())\n",
    "sm = plt.cm.ScalarMappable(cmap=my_cmap)\n",
    "cbar = plt.colorbar(sm, ax=ax2)\n",
    "cbar.ax.set_xlabel('sim-weight', rotation=0)\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.show()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "fig.set_size_inches(18.5, 5.25)\n",
    "sns.lineplot(x=\"eval-postprocessing-threshold\", y=\"PRECISION\", hue=\"sim-weight\", data=df_macro_avg, ax = ax1, palette= sns.color_palette(\"Reds_d\", 11));\n",
    "ax1.set_title(\"Macro\")\n",
    "ax1.set_ylabel(\"Precision\")\n",
    "ax1.set_ylim([0.0,1.0])\n",
    "ax1.set_xlabel(\"Post-processing Threshold\")\n",
    "ax1.get_legend().remove()\n",
    "my_cmap = ListedColormap(sns.color_palette(\"Reds_d\", 11).as_hex())\n",
    "sm = plt.cm.ScalarMappable(cmap=my_cmap)\n",
    "cbar = fig.colorbar(sm, ax=ax1)\n",
    "cbar.ax.set_visible(False)\n",
    "cbar.ax.set_xlabel('sim-weight', rotation=0)\n",
    "sns.lineplot(x=\"eval-postprocessing-threshold\", y=\"PRECISION\", hue=\"sim-weight\", data=df_micro_avg, ax = ax2, palette= sns.color_palette(\"Reds_d\", 11));\n",
    "ax2.set_title(\"Micro\")\n",
    "ax2.set_ylabel(\"Precision\")\n",
    "ax2.set_ylim([0.0,1.0])\n",
    "ax2.set_xlabel(\"Post-processing Threshold\")\n",
    "ax2.get_legend().remove()\n",
    "my_cmap = ListedColormap(sns.color_palette(\"Reds_d\", 11).as_hex())\n",
    "sm = plt.cm.ScalarMappable(cmap=my_cmap)\n",
    "cbar = plt.colorbar(sm, ax=ax2)\n",
    "cbar.ax.set_xlabel('sim-weight', rotation=0)\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "sns.set_palette(sns.color_palette(\"Reds_d\", 11))\n",
    "fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "fig.set_size_inches(18.5, 5.25)\n",
    "sns.lineplot(x=\"eval-postprocessing-threshold\", y=\"FSCORE\", hue=\"sim-weight\", data=df_macro_avg, ax = ax1, palette= sns.color_palette(\"Reds_d\", 11));\n",
    "ax1.set_title(\"Macro\")\n",
    "ax1.set_ylim([0.0,1.0])\n",
    "ax1.set_ylabel(\"Fscore\")\n",
    "ax1.set_xlabel(\"Post-processing Threshold\")\n",
    "ax1.get_legend().remove()\n",
    "my_cmap = ListedColormap(sns.color_palette(\"Reds_d\", 11).as_hex())\n",
    "sm = plt.cm.ScalarMappable(cmap=my_cmap)\n",
    "cbar = fig.colorbar(sm, ax=ax1)\n",
    "cbar.ax.set_visible(False)\n",
    "cbar.ax.set_xlabel('sim-weight', rotation=0)\n",
    "\n",
    "sns.lineplot(x=\"eval-postprocessing-threshold\", y=\"FSCORE\", hue=\"sim-weight\", data=df_micro_avg, ax = ax2, palette=sns.color_palette(\"Reds_d\", 11));\n",
    "ax2.set_title(\"Micro\")\n",
    "ax2.set_ylim([0.0,1.0])\n",
    "ax2.set_ylabel(\"Fscore\")\n",
    "ax2.set_xlabel(\"Post-processing Threshold\")\n",
    "ax2.get_legend().remove()\n",
    "my_cmap = ListedColormap(sns.color_palette(\"Reds_d\", 11).as_hex())\n",
    "sm = plt.cm.ScalarMappable(cmap=my_cmap)\n",
    "cbar = fig.colorbar(sm, ax = ax2)\n",
    "cbar.ax.set_visible(True)\n",
    "cbar.ax.set_xlabel('sim-weight', rotation=0)\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#avg fscore for each matcher depending on A) the sim weight B) the \n",
    "df_macro_avg = df_combined[df_combined.Name == \"Aggregated (MACRO)\"]\n",
    "df_micro_avg = df_combined[df_combined.Name == \"Aggregated (MICRO)\"]\n",
    "\n",
    "matchers = set(df_macro_avg[\"matcher_wo_weight\"].values)\n",
    "for m in matchers:\n",
    "    df_macro_avg_fscore = df_macro_avg[df_macro_avg[\"matcher_wo_weight\"] == m].pivot(\"sim-weight\", \"eval-postprocessing-threshold\", \"FSCORE\")\n",
    "    df_micro_avg_fscore = df_micro_avg[df_micro_avg[\"matcher_wo_weight\"] == m].pivot(\"sim-weight\", \"eval-postprocessing-threshold\", \"FSCORE\")\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "    fig.set_size_inches(18.5, 5.25)\n",
    "\n",
    "    sns.heatmap(df_macro_avg_fscore, ax = ax1, vmin = 0)\n",
    "    ax1.set_title(\"Macro Fscore\")\n",
    "    ax1.set_xlabel(\"Post-processing Threshold\")\n",
    "    sns.heatmap(df_micro_avg_fscore, ax = ax2, vmin = 0)\n",
    "    ax2.set_title(\"Micro Fscore\")\n",
    "    ax2.set_xlabel(\"Post-processing Threshold\")\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fscore by number to match items \n",
    "fig, (ax1) = plt.subplots(1,1)\n",
    "fig.set_size_inches(18.5, 5.25)\n",
    "sns.lineplot(x=\"sumNonTaus\", y=\"FSCORE\", hue=\"matcher\", data=df_combined);\n",
    "plt.title(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#runtime analysis\n",
    "df_ = df_combined[df_combined[\"Name\"] != \"Aggregated (MICRO)\"]\n",
    "df_ = df_[df_[\"Name\"] != \"Aggregated (MACRO)\"]\n",
    "\n",
    "\n",
    "# time wrt behavioral share\n",
    "fig, (ax1) = plt.subplots(1,1)\n",
    "fig.set_size_inches(18.5, 5.25)\n",
    "sns.lineplot(x=\"sim-weight\", y=\"LP TIME\", hue=\"matcher_wo_weight\", data=df_, ax=ax1);\n",
    "plt.title(\"LP Time wrt sim weight\")\n",
    "#plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "#boxplots for each matcher\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(1,4)\n",
    "fig.set_size_inches(18.5, 5.25)\n",
    "sns.boxplot(x=\"matcher\", y=\"OVERALL TIME\", data=df_, ax=ax1, color='skyblue')\n",
    "ax1.set_xticklabels(ax1.get_xticklabels(),rotation=90)\n",
    "ax1.set_title(\"Overall Time\")\n",
    "ax1.set_ylabel(\"Time\")\n",
    "sns.boxplot(x=\"matcher\", y=\"LP TIME\", data=df_, ax=ax2, color='skyblue')\n",
    "ax2.set_xticklabels(ax2.get_xticklabels(),rotation=90)\n",
    "ax2.set_title(\"Time to solve LP\")\n",
    "ax2.set_ylabel(\"Time\")\n",
    "sns.boxplot(x=\"matcher\", y=\"BP TIME\", data=df_, ax=ax3, color='skyblue')\n",
    "ax3.set_xticklabels(ax3.get_xticklabels(),rotation=90)\n",
    "ax3.set_title(\"Time to compute Relational Profile\")\n",
    "ax3.set_ylabel(\"Time\")\n",
    "sns.boxplot(x=\"matcher\", y=\"LABEL-SIM TIME\", data=df_, ax=ax4, color='skyblue')\n",
    "ax4.set_xticklabels(ax4.get_xticklabels(),rotation=90)\n",
    "ax4.set_title(\"Time to compute Label Similarity\")\n",
    "ax4.set_ylabel(\"Time\")\n",
    "fig.suptitle(\"Aggregated Time in seconds per Matcher\")\n",
    "\n",
    "# sum of tau transitions analysis\n",
    "fig, (ax1) = plt.subplots(1,1)\n",
    "fig.set_size_inches(18.5, 5.25)\n",
    "sns.lineplot(x=\"sumNonTaus\", y=\"LP TIME\", hue=\"matcher\", data=df_, ax=ax1);\n",
    "plt.title(\"LP Time wrt non-silentTransitions\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "#heatmap time\n",
    "matchers = list(set(df_[\"matcher\"].values))\n",
    "fig, ax = plt.subplots(int((len(matchers)+1)/2),2)\n",
    "axli = ax.flatten()\n",
    "fig.set_size_inches(18.5, 5.25)\n",
    "fig.suptitle(\"Avg. LP Time by non silent transition number\")\n",
    "for i,m in enumerate(matchers, start=0):\n",
    "    df_pivot = pd.pivot_table(df_[df_['matcher'] == m], values='LP TIME', index=['net1NonTaus'], columns=['net2NonTaus'],aggfunc=np.mean)\n",
    "    sns.heatmap(df_pivot, ax = axli[i])\n",
    "    axli[i].set_title(m)\n",
    "\n",
    "#Visualize Runtime\n",
    "g = sns.catplot(x=\"Name\", y=\"LP TIME\", hue=\"matcher\", kind=\"bar\", data=df_combined,  height=5, aspect=4);\n",
    "g.set_xticklabels(rotation=90)\n",
    "\n",
    "#Visualize Runtime\n",
    "g = sns.catplot(x=\"Name\", y=\"LABEL-SIM TIME\", hue=\"matcher\", kind=\"bar\", data=df_combined,  height=5, aspect=4);\n",
    "g.set_xticklabels(rotation=90)\n",
    "\n",
    "#Visualize Runtime\n",
    "g = sns.catplot(x=\"Name\", y=\"BP TIME\", hue=\"matcher\", kind=\"bar\", data=df_combined,  height=5, aspect=4);\n",
    "g.set_xticklabels(rotation=90)\n",
    "\n",
    "#Visualize Runtime\n",
    "g = sns.catplot(x=\"Name\", y=\"OVERALL TIME\", hue=\"matcher\", kind=\"bar\", data=df_combined,  height=5, aspect=4);\n",
    "g.set_xticklabels(rotation=90)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
